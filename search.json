[{"path":[]},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement Corrado.Lanera@ubep.unipd.. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, available https://www.contributor-covenant.org/version/2/1/code_of_conduct.html. Community Impact Guidelines inspired [Mozilla’s code conduct enforcement ladder][https://github.com/mozilla/inclusion]. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 CorradoLanera Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Corrado Lanera. Author, maintainer.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lanera C (2024). ubep.gpt: basic/simple interface OpenAI’s GPT API. R package version 0.2.1,  https://ubesp-dctv.github.io/ubep.gpt/, https://github.com/UBESP-DCTV/ubep.gpt.","code":"@Manual{,   title = {ubep.gpt: A basic/simple interface to OpenAI’s GPT API},   author = {Corrado Lanera},   year = {2024},   note = {R package version 0.2.1,  https://ubesp-dctv.github.io/ubep.gpt/},   url = {https://github.com/UBESP-DCTV/ubep.gpt}, }"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/index.html","id":"ubepgpt","dir":"","previous_headings":"","what":"A basic/simple interface to OpenAI’s GPT API","title":"A basic/simple interface to OpenAI’s GPT API","text":"goal ubep.gpt provide basic/simple interface OpenAI’s GPT API. package designed work dataframes/tibbles simplify process querying API.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A basic/simple interface to OpenAI’s GPT API","text":"can install development version ubep.gpt like :","code":"remotes::install_github(\"UBESP-DCTV/ubep.gpt\")"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/index.html","id":"basic-example","dir":"","previous_headings":"","what":"Basic example","title":"A basic/simple interface to OpenAI’s GPT API","text":"can use query_gpt function query GPT API. can decide use GPT-3.5-turbo GPT-4-turbo models. function useful mainly iterate query decided number times (10 default) case error (often caused server overload). use function need compose prompt. can use compose_prompt_api function compose prompt. function useful helps compose prompt automatically adopting required API’s structure. queried API, can extract content response using get_content function. can also extract tokens prompt response using get_tokens function.","code":"library(ubep.gpt) #> Wellcome to ubep.gpt! #> The OPENAI_API_KEY environment variable is set #> You are ready to use the package `ubep.gpt`. #> Just, double check if the key is the correct one. #> REMIND: Never share your API key with others. #>       Keep it safe and secure. #>       If you think that your API key was compromised, #>       you can regenerate it in the OpenAI-API website #>       (https://platform.openai.com/api-keys). #> Enjoy the package! prompt <- compose_prompt_api(   sys_prompt = \"You are the assistant of a university professor.\",   usr_prompt = \"Tell me about the last course you provided.\" ) prompt #> [[1]] #> [[1]]$role #> [1] \"system\" #>  #> [[1]]$content #> [1] \"You are the assistant of a university professor.\" #>  #>  #> [[2]] #> [[2]]$role #> [1] \"user\" #>  #> [[2]]$content #> [1] \"Tell me about the last course you provided.\"  res <- query_gpt(   prompt = prompt,   model = \"gpt-3.5-turbo\",   quiet = FALSE, # default TRUE   max_try = 2, # default 10   temperature = 1.5, # default 0 [0-2]   max_tokens = 100 # default 1000 ) #> ℹ Total tries: 1. #> ℹ Prompt token used: 29. #> ℹ Response token used: 100. #> ℹ Total token used: 129.  str(res) #> List of 7 #>  $ id                : chr \"chatcmpl-9IqTC7CEErC0eZyGBfuCqAph0YROG\" #>  $ object            : chr \"chat.completion\" #>  $ created           : int 1714278626 #>  $ model             : chr \"gpt-3.5-turbo-0125\" #>  $ choices           :'data.frame':  1 obs. of  5 variables: #>   ..$ index          : int 0 #>   ..$ logprobs       : logi NA #>   ..$ finish_reason  : chr \"length\" #>   ..$ message.role   : chr \"assistant\" #>   ..$ message.content: chr \"Sure! The course was titled \\\"Advanced Topics in Neuroscience\\\" and it was a graduate-level seminar course that\"| __truncated__ #>  $ usage             :List of 3 #>   ..$ prompt_tokens    : int 29 #>   ..$ completion_tokens: int 100 #>   ..$ total_tokens     : int 129 #>  $ system_fingerprint: chr \"fp_3b956da36b\" get_content(res) #> [1] \"Sure! The course was titled \\\"Advanced Topics in Neuroscience\\\" and it was a graduate-level seminar course that covered cutting-edge research in the field of neuroscience. Students delved into recent neuroscientific articles, discussed topics such as brain connectivity, neural circuit function, and the role of various neurotransmitters in behavior. The course concluded with each student giving a presentation on a specific topic of their choice, showcasing their understanding and ability to critically analyze research findings in the field. Many students found the course challenging and engaging\" get_tokens(res) #> [1] 129 get_tokens(res, \"prompt\") #> [1] 29 get_tokens(res, \"all\") #>     prompt_tokens completion_tokens      total_tokens  #>                29               100               129"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/index.html","id":"easy-prompt-assisted-creation","dir":"","previous_headings":"","what":"Easy prompt-assisted creation","title":"A basic/simple interface to OpenAI’s GPT API","text":"can use compose_sys_prompt compose_usr_prompt functions create system user prompts, respectively. functions useful help compose prompts following best practices composing prompt. fact arguments just main components every prompt . just , composing prompt juxtaposing components right order.","code":"sys_prompt <- compose_sys_prompt(   role = \"You are the assistant of a university professor.\",   context = \"You are analyzing the comments of the students of the last course.\" ) cat(sys_prompt) #> You are the assistant of a university professor. #> You are analyzing the comments of the students of the last course.  usr_prompt <- compose_usr_prompt(   task = \"Your task is to extract information from a text provided.\",   instructions = \"You should extract the first and last words of the text.\",   output = \"Return the first and last words of the text separated by a dash, i.e., `first - last`.\",   style = \"Do not add any additional information, return only the requested information.\",   examples = \"     # Examples:     text: 'This is an example text.'     output: 'This - text'     text: 'Another example text!!!'     output: 'Another - text'\",   text = \"Nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura\" ) cat(usr_prompt) #> Your task is to extract information from a text provided. #> You should extract the first and last words of the text. #> Return the first and last words of the text separated by a dash, i.e., `first - last`. #> Do not add any additional information, return only the requested information. #>  #>     # Examples: #>     text: 'This is an example text.' #>     output: 'This - text' #>     text: 'Another example text!!!' #>     output: 'Another - text' #> \"\"\"\" #> Nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura #> \"\"\"\"  compose_prompt_api(sys_prompt, usr_prompt) |>    query_gpt() |>    get_content() #> [1] \"Nel - oscura\""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/index.html","id":"querying-a-column-of-a-dataframe","dir":"","previous_headings":"","what":"Querying a column of a dataframe","title":"A basic/simple interface to OpenAI’s GPT API","text":"can use query_gpt_on_column function query GPT API column dataframe. function useful helps iterate query row column compose prompt automatically adopting required API’s structure. case, need provide components prompt creating prompt template, name column embed template “text” query. prompt’s components optional, can provide ones need: role context compose system prompt, task, instructions, output, style, examples compose user prompt (just juxtaposed right order)","code":"db <- data.frame(   txt = c(     \"I'm very satisfied with the course; it was very interesting and useful.\",     \"I didn't like it at all; it was deadly boring.\",     \"The best course I've ever attended.\",     \"The course was a waste of time.\",     \"blah blah blah\",     \"woow\",     \"bim bum bam\"   ) )  # system role <- \"You are the assistant of a university professor.\" context <- \"You are analyzing the comments of the students of the last course.\"  # user task <- \"Your task is to understand if they are satisfied with the course.\" instructions <- \"Analyze the comments and decide if they are satisfied or not.\" output <- \"Report 'satisfied' or 'unsatisfied', in case of doubt or impossibility report 'NA'.\" style <- \"Do not add any comment, return only and exclusively one of the possible classifications.\"  examples <- \"   # Examples:   text: 'I'm very satisfied with the course; it was very interesting and useful.'   output: 'satisfied'   text: 'I didn't like it at all; it was deadly boring.'   output: 'unsatisfied'\"  sys_prompt <- compose_sys_prompt(role = role, context = context) usr_prompt <- compose_usr_prompt(   task = task,   instructions = instructions,   output = output,   style = style,   examples = examples )  db |>  query_gpt_on_column(    \"txt\",    sys_prompt = sys_prompt,    usr_prompt = usr_prompt,  ) #> # A tibble: 7 × 2 #>   txt                                                                    gpt_res #>   <chr>                                                                  <chr>   #> 1 I'm very satisfied with the course; it was very interesting and usefu… satisf… #> 2 I didn't like it at all; it was deadly boring.                         unsati… #> 3 The best course I've ever attended.                                    satisf… #> 4 The course was a waste of time.                                        unsati… #> 5 blah blah blah                                                         <NA>    #> 6 woow                                                                   <NA>    #> 7 bim bum bam                                                            <NA>"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/index.html","id":"base-chatgpt-prompt-creation-not-for-api","dir":"","previous_headings":"","what":"Base ChatGPT prompt creation (NOT for API)","title":"A basic/simple interface to OpenAI’s GPT API","text":"can use compose_prompt function create prompt ChatGPT. function useful helps compose prompt following best practices composing prompt. fact arguments just main components every prompt . just , composing prompt juxtaposing components right order. result suitable copy-pasted ChatGPT, used API calls, .e., used query_gpt function!! https://chat.openai.com/share/394a008b-d463-42dc-9361-1bd745bcad6d","code":"prompt <- compose_prompt(   role = \"You are the assistant of a university professor.\",   context = \"You are analyzing the comments of the students of the last course.\",   task = \"Your task is to extract information from a text provided.\",   instructions = \"You should extract the first and last words of the text.\",   output = \"Return the first and last words of the text separated by a dash, i.e., `first - last`.\",   style = \"Do not add any additional information, return only the requested information.\",   examples = \"     # Examples:     text: 'This is an example text.'     output: 'This - text'     text: 'Another example text!!!'     output: 'Another - text'\",   text = \"Nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura\" )  cat(prompt) #> You are the assistant of a university professor. #> You are analyzing the comments of the students of the last course. #> Your task is to extract information from a text provided. #> You should extract the first and last words of the text. #> Return the first and last words of the text separated by a dash, i.e., `first - last`. #> Do not add any additional information, return only the requested information. #>  #>     # Examples: #>     text: 'This is an example text.' #>     output: 'This - text' #>     text: 'Another example text!!!' #>     output: 'Another - text' #> \"\"\"\" #> Nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura #> \"\"\"\""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"A basic/simple interface to OpenAI’s GPT API","text":"Please note ubep.gpt project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a prompt to ChatGPT — compose_prompt","title":"Create a prompt to ChatGPT — compose_prompt","text":"function simple wrapper compose good prompt ChatGPT. output nothing juxtaposition separate lines various components (additional text enclosed delimiters bottom prompt). use focused useful remembering getting used entering components useful good prompt.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a prompt to ChatGPT — compose_prompt","text":"","code":"compose_prompt(   role = NULL,   context = NULL,   task = NULL,   instructions = NULL,   output = NULL,   style = NULL,   examples = NULL,   text = NULL,   delimiter = if (is.null(text)) NULL else \"\\\"\\\"\\\"\\\"\" )  compose_sys_prompt(role = NULL, context = NULL)  compose_usr_prompt(   task = NULL,   instructions = NULL,   output = NULL,   style = NULL,   examples = NULL,   text = NULL,   delimiter = if (is.null(text)) NULL else \"\\\"\\\"\\\"\\\"\" )"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a prompt to ChatGPT — compose_prompt","text":"role (chr) role ChatGPT play context (chr) context behind task required task (chr) tasks ChatGPT assess instructions (chr) Description steps ChatGPT follow output (chr) type/kind output required style (chr) style ChatGPT use output examples (chr) examples correct output text (chr) Additional text embed prompt delimiter (chr) delimiters text embed, sequence three identical symbols suggested","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a prompt to ChatGPT — compose_prompt","text":"(chr) glue prompts components (chr) complete system prompt (chr) complete user prompt","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Create a prompt to ChatGPT — compose_prompt","text":"compose_sys_prompt(): compose_usr_prompt():","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a prompt to ChatGPT — compose_prompt","text":"","code":"if (FALSE) {   compose_prompt(     role = \"Sei l'assistente di un docente universitario.\",     context = \"       Tu e lui state preparando un workshop sull'utilizzo di ChatGPT       per biostatisitci ed epidemiologi.\",     task = \"       Il tuo compito è trovare cosa dire per spiegare cosa sia una       chat di ChatGPT agli studenti, considerando che potrebbe       esserci qualcuno che non ne ha mai sentito parlare (e segue       il worksho incuriosito dal titolo o dagli amici).\",     output = \"       Riporta un potenziale dialogo tra il docente e gli studenti       che assolva ed esemplifichi lo scopo descritto.\",    style = \"Usa un tono amichevole, colloquiale, ma preciso.\"  ) } if (FALSE) {   msg_sys <- compose_sys_prompt(     role = \"Sei l'assistente di un docente universitario.\",     context = \"       Tu e lui state preparando un workshop sull'utilizzo di ChatGPT       per biostatisitci ed epidemiologi.\"  ) }   msg_usr <- compose_usr_prompt(     task = \"       Il tuo compito è trovare cosa dire per spiegare cosa sia una       chat di ChatGPT agli studenti, considerando che potrebbe       esserci qualcuno che non ne ha mai sentito parlare (e segue       il worksho incuriosito dal titolo o dagli amici).\",     output = \"       Riporta un potenziale dialogo tra il docente e gli studenti       che assolva ed esemplifichi lo scopo descritto.\",    style = \"Usa un tono amichevole, colloquiale, ma preciso.\"  )"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt_api.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a prompt to OpenAI API — compose_prompt_api","title":"Create a prompt to OpenAI API — compose_prompt_api","text":"Questa funzione è un semplice wrapper per comporre un prompt per le API OpenAI ChatGPT. Per la sua semplicità, per lo più didattica, non considera alternanze successive di prompt nella chat ma solo l'impostazione iniziale del sistema e il primo messaggio dell'utente.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt_api.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a prompt to OpenAI API — compose_prompt_api","text":"","code":"compose_prompt_api(sys_prompt = NULL, usr_prompt = NULL)"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt_api.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a prompt to OpenAI API — compose_prompt_api","text":"sys_prompt (chr) messaggio da usare per impostare il sistema usr_prompt (chr) messaggio da usare come richiesta al sistema passata dall'utente","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt_api.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a prompt to OpenAI API — compose_prompt_api","text":"(chr) una lista di due lista, la prima con il messaggio da usare per il prompt di impostazione del sistema di assistenza delle API, la seconda con il prompt di richiesta dell'utente.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt_api.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a prompt to OpenAI API — compose_prompt_api","text":"genere, una conversazione è formattata con un messaggio di sistema, seguito da messaggi alternati dell'utente e dell'assistente. Il messaggio di sistema consente di impostare il comportamento dell'assistente. Ad esempio, è possibile modificare la personalità dell'assistente o fornire istruzioni specifiche sul comportamento da tenere durante la conversazione. Tuttavia, il messaggio di sistema è facoltativo e il comportamento del modello senza un messaggio di sistema sarà probabilmente simile quello di un messaggio generico come \"Sei un assistente utile\". messaggi dell'utente forniscono richieste o commenti cui l'assistente deve rispondere. messaggi dell'assistente memorizzano le risposte precedenti dell'assistente, ma possono anche essere scritti dall'utente per fornire esempi del comportamento desiderato.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/compose_prompt_api.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a prompt to OpenAI API — compose_prompt_api","text":"","code":"msg_sys <- compose_sys_prompt(   role = \"Sei l'assistente di un docente universitario.\",   context = \"     Tu e lui state preparando un workshop sull'utilizzo di ChatGPT     per biostatisitci ed epidemiologi.\"  )  msg_usr <- compose_usr_prompt(   task = \"     Il tuo compito è trovare cosa dire per spiegare cosa sia una     chat di ChatGPT agli studenti, considerando che potrebbe     esserci qualcuno che non ne ha mai sentito parlare (e segue     il worksho incuriosito dal titolo o dagli amici).\",   output = \"     Riporta un potenziale dialogo tra il docente e gli studenti     che assolva ed esemplifichi lo scopo descritto.\",  style = \"Usa un tono amichevole, colloquiale, ma preciso.\" )  compose_prompt_api(msg_sys, msg_usr) #> [[1]] #> [[1]]$role #> [1] \"system\" #>  #> [[1]]$content #> [1] \"Sei l'assistente di un docente universitario.\\n\\n    Tu e lui state preparando un workshop sull'utilizzo di ChatGPT\\n    per biostatisitci ed epidemiologi.\" #>  #>  #> [[2]] #> [[2]]$role #> [1] \"user\" #>  #> [[2]]$content #> [1] \"\\n    Il tuo compito è trovare cosa dire per spiegare cosa sia una\\n    chat di ChatGPT agli studenti, considerando che potrebbe\\n    esserci qualcuno che non ne ha mai sentito parlare (e segue\\n    il worksho incuriosito dal titolo o dagli amici).\\n\\n    Riporta un potenziale dialogo tra il docente e gli studenti\\n    che assolva ed esemplifichi lo scopo descritto.\\nUsa un tono amichevole, colloquiale, ma preciso.\" #>  #>"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/create_usr_data_prompter.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a function to prompt the user for data — create_usr_data_prompter","title":"Create a function to prompt the user for data — create_usr_data_prompter","text":"function create function can used prompt user data specific context. Given interested context, function created accept string text input return complete prompt based desired context.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/create_usr_data_prompter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a function to prompt the user for data — create_usr_data_prompter","text":"","code":"create_usr_data_prompter(usr_prompt = NULL)"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/create_usr_data_prompter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a function to prompt the user for data — create_usr_data_prompter","text":"usr_prompt (chr) user prompt use template text added.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/create_usr_data_prompter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a function to prompt the user for data — create_usr_data_prompter","text":"(function) function can used prompt user, accepting string text input returning complete prompt based desired context.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/create_usr_data_prompter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a function to prompt the user for data — create_usr_data_prompter","text":"","code":"usr_prmpt <- compose_prompt(   role = \"You are the assistant of a university professor.\",   context = \"     You are analyzing the comments of the students of the last course.\",   task = \"Your task is to extract information from a text provided.\",   instructions = \"     You should extract the first and last words of the text.\",   output = \"     Return the first and last words of the text separated by a dash,     i.e., `first - last`.\",   style = \"     Do not add any additional information,     return only the requested information.\",   examples = \"       # Examples:       text: 'This is an example text.'       output: 'This - text'       text: 'Another example text!!!'       output: 'Another - text'\"   ) prompter <- create_usr_data_prompter(   usr_prompt = usr_prmpt ) prompter(\"This is an example text.\") #> [1] \"You are the assistant of a university professor.\\n\\n    You are analyzing the comments of the students of the last course.\\nYour task is to extract information from a text provided.\\n\\n    You should extract the first and last words of the text.\\n\\n    Return the first and last words of the text separated by a dash,\\n    i.e., `first - last`.\\n\\n    Do not add any additional information,\\n    return only the requested information.\\n\\n      # Examples:\\n      text: 'This is an example text.'\\n      output: 'This - text'\\n      text: 'Another example text!!!'\\n      output: 'Another - text'\\n\\\"\\\"\\\"\\\"\\nThis is an example text.\\n\\\"\\\"\\\"\\\"\" prompter(\"Another example text!!!\") #> [1] \"You are the assistant of a university professor.\\n\\n    You are analyzing the comments of the students of the last course.\\nYour task is to extract information from a text provided.\\n\\n    You should extract the first and last words of the text.\\n\\n    Return the first and last words of the text separated by a dash,\\n    i.e., `first - last`.\\n\\n    Do not add any additional information,\\n    return only the requested information.\\n\\n      # Examples:\\n      text: 'This is an example text.'\\n      output: 'This - text'\\n      text: 'Another example text!!!'\\n      output: 'Another - text'\\n\\\"\\\"\\\"\\\"\\nAnother example text!!!\\n\\\"\\\"\\\"\\\"\"  # You can also use it with a data frame to programmaically create # prompts for each row of a data frame's column. db <- data.frame(   text = c(\"This is an example text.\", \"Another example text!!!\") ) db$text |> purrr::map_chr(prompter) #> [1] \"You are the assistant of a university professor.\\n\\n    You are analyzing the comments of the students of the last course.\\nYour task is to extract information from a text provided.\\n\\n    You should extract the first and last words of the text.\\n\\n    Return the first and last words of the text separated by a dash,\\n    i.e., `first - last`.\\n\\n    Do not add any additional information,\\n    return only the requested information.\\n\\n      # Examples:\\n      text: 'This is an example text.'\\n      output: 'This - text'\\n      text: 'Another example text!!!'\\n      output: 'Another - text'\\n\\\"\\\"\\\"\\\"\\nThis is an example text.\\n\\\"\\\"\\\"\\\"\" #> [2] \"You are the assistant of a university professor.\\n\\n    You are analyzing the comments of the students of the last course.\\nYour task is to extract information from a text provided.\\n\\n    You should extract the first and last words of the text.\\n\\n    Return the first and last words of the text separated by a dash,\\n    i.e., `first - last`.\\n\\n    Do not add any additional information,\\n    return only the requested information.\\n\\n      # Examples:\\n      text: 'This is an example text.'\\n      output: 'This - text'\\n      text: 'Another example text!!!'\\n      output: 'Another - text'\\n\\\"\\\"\\\"\\\"\\nAnother example text!!!\\n\\\"\\\"\\\"\\\"\""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/get_completion_from_messages.html","id":null,"dir":"Reference","previous_headings":"","what":"Get completion from chat messages — get_completion_from_messages","title":"Get completion from chat messages — get_completion_from_messages","text":"Get completion chat messages Get content chat completion Get number token chat completion","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/get_completion_from_messages.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get completion from chat messages — get_completion_from_messages","text":"","code":"get_completion_from_messages(   messages,   model = \"gpt-3.5-turbo\",   temperature = 0,   max_tokens = NULL,   endpoint = \"https://api.openai.com/v1/chat/completions\" )  get_content(completion)  get_tokens(completion, what = c(\"total\", \"prompt\", \"completion\", \"all\"))"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/get_completion_from_messages.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get completion from chat messages — get_completion_from_messages","text":"messages (list) following format: ⁠list(list(\"role\" = \"user\", \"content\" = \"Hey! old ?\") (see: https://platform.openai.com/docs/api-reference/chat/create#chat/create-model) model (chr, default = \"gpt-3.5-turbo\") length one character vector indicating model use (see: https://platform.openai.com/docs/models/continuous-model-upgrades) temperature (dbl, default = 0) value 0 (deterministic answer) 2 (random). (see: https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature) max_tokens (dbl, default = 500) value greater 0. maximum number tokens generate chat completion. (see: https://platform.openai.com/docs/api-reference/chat/create#chat/create-max_tokens) endpoint (chr, default = \"https://api.openai.com/v1/chat/completions\", .e. OpenAI API) endpoint use request. completion number tokens used output get_completion_from_messages call (chr) one \"total\" (default), \"prompt\", \"completion\", \"\"","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/get_completion_from_messages.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get completion from chat messages — get_completion_from_messages","text":"(list) two element: content, contains chr vector response, tokens, list number tokens used request (prompt_tokens), answer (completion_tokens), overall (total_tokens, sum two) (chr) output message returned assistant (int) number token used completion prompt completion part, overall (total)","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/get_completion_from_messages.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get completion from chat messages — get_completion_from_messages","text":"argument description, please refer official documentation. Lower values temperature result consistent outputs, higher values generate diverse creative results. Select temperature value based desired trade-coherence creativity specific application. Setting temperature 0 make outputs mostly deterministic, small amount variability remain.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/get_completion_from_messages.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Get completion from chat messages — get_completion_from_messages","text":"get_content(): get_tokens():","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/get_completion_from_messages.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get completion from chat messages — get_completion_from_messages","text":"","code":"if (FALSE) {   prompt <- list(     list(       role = \"system\",       content = \"you are an assistant who responds succinctly\"     ),     list(       role = \"user\",       content = \"Return the text: 'Hello world'.\"     )   )   res <- get_completion_from_messages(prompt)   answer <- get_content(res) # \"Hello world.\"   token_used <- get_tokens(res) # 30 }  if (FALSE) {   msg_sys <- compose_sys_prompt(     role = \"Sei l'assistente di un docente universitario.\",     context = \"       Tu e lui state preparando un workshop sull'utilizzo di ChatGPT       per biostatisitci ed epidemiologi.\"   )    msg_usr <- compose_usr_prompt(     task = \"       Il tuo compito è trovare cosa dire per spiegare cosa sia una       chat di ChatGPT agli studenti, considerando che potrebbe       esserci qualcuno che non ne ha mai sentito parlare (e segue       il worksho incuriosito dal titolo o dagli amici).\",     output = \"       Riporta un potenziale dialogo tra il docente e gli studenti       che assolva ed esemplifichi lo scopo descritto.\",     style = \"Usa un tono amichevole, colloquiale, ma preciso.\"   )    prompt <- compose_prompt_api(msg_sys, msg_usr)   res <- get_completion_from_messages(prompt, \"gpt-4-turbo\")   answer <- get_content(res)   token_used <- get_tokens(res) }"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Query the GPT model — query_gpt","title":"Query the GPT model — query_gpt","text":"Query GPT model","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query the GPT model — query_gpt","text":"","code":"query_gpt(   prompt,   model = \"gpt-3.5-turbo\",   temperature = 0,   max_tokens = NULL,   endpoint = \"https://api.openai.com/v1/chat/completions\",   max_try = 10,   quiet = TRUE,   na_if_error = FALSE )"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query the GPT model — query_gpt","text":"prompt (chr) prompt use model (chr) model use temperature (dbl) temperature use max_tokens (dbl) maximum number tokens endpoint (chr, default = \"https://api.openai.com/v1/chat/completions\", .e. OpenAI API) endpoint use request. max_try (int) maximum number tries quiet (lgl) whether print information na_if_error (lgl) whether return NA error occurs","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query the GPT model — query_gpt","text":"(list) result query","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query the GPT model — query_gpt","text":"","code":"if (FALSE) {  prompt <- compose_prompt_api(    sys_prompt = compose_sys_prompt(      role = \"Sei l'assistente di un docente universitario.\",      context = \"        Tu e lui state preparando un workshop sull'utilizzo di ChatGPT        per biostatisitci ed epidemiologi.\"    ),    usr_prompt = compose_usr_prompt(      task = \"        Il tuo compito è trovare cosa dire per spiegare cosa sia una        chat di ChatGPT agli studenti, considerando che potrebbe        esserci qualcuno che non ne ha mai sentito parlare (e segue        il worksho incuriosito dal titolo o dagli amici).\",      output = \"        Riporta un potenziale dialogo tra il docente e gli studenti        che assolva ed esemplifichi lo scopo descritto.\",      style = \"Usa un tono amichevole, colloquiale, ma preciso.\"    )  )  res <- query_gpt(prompt)  get_content(res)  get_tokens(res) }"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt_on_column.html","id":null,"dir":"Reference","previous_headings":"","what":"Query GPT on a dataframe's column — query_gpt_on_column","title":"Query GPT on a dataframe's column — query_gpt_on_column","text":"Query GPT dataframe's column","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt_on_column.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query GPT on a dataframe's column — query_gpt_on_column","text":"","code":"query_gpt_on_column(   db,   text_column,   sys_prompt = NULL,   usr_prompt = NULL,   model = \"gpt-3.5-turbo\",   quiet = TRUE,   max_try = 10,   temperature = 0,   max_tokens = NULL,   endpoint = \"https://api.openai.com/v1/chat/completions\",   include_source_text = TRUE,   simplify = TRUE,   na_if_error = FALSE )"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt_on_column.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query GPT on a dataframe's column — query_gpt_on_column","text":"db (data.frame) data use text_column (chr) name column containing text data sys_prompt (chr) system prompt use usr_prompt (chr) user prompt use model (chr, default = \"gpt-3.5-turbo\") model use quiet (lgl, default = TRUE) whether print information max_try (int, default = 10) maximum number tries temperature (dbl, default = 0) temperature use max_tokens (dbl, default = 1000) maximum number tokens endpoint (chr, default = \"https://api.openai.com/v1/chat/completions\", .e. OpenAI API) endpoint use request. include_source_text (lgl, default = TRUE) whether include source text simplify (lgl, default = TRUE) whether simplify output na_if_error (lgl, default = FALSE) whether return NA error occurs","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt_on_column.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query GPT on a dataframe's column — query_gpt_on_column","text":"(tibble) result query","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/query_gpt_on_column.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query GPT on a dataframe's column — query_gpt_on_column","text":"","code":"if (FALSE) {   db <- tibble(    commenti = c(      \"Che barba, che noia!\",      \"Un po' noioso, ma interessante\",      \"Che bello, mi è piaciuto molto!\"    )  )   role <- \"Sei l'assistente di un docente universitario.\"  context <- \"State analizzando i commenti degli studenti dell'ultimo corso.\"  task <- \"Il tuo compito è capire se sono soddisfatti del corso.\"  instructions <- \"Analizza i commenti e decidi se sono soddisfatti o meno.\"  output <- \"Riporta 'soddisfatto' o 'insoddisfatto'.\"  style <- \"Non aggiungere nessun commento, restituisci solo ed    esclusivamente la classificazione.\"  examples <- \"  commento_1: 'Mi è piaciuto molto il corso; davvero interessante.'  classificazione_1: 'soddisfatto'  commento_2: 'Non mi è piaciuto per niente; una noia mortale'  classificazione_2: 'insoddisfatto'  \"   sys_prompt <- compose_sys_prompt(role = role, context = context)  usr_prompt <- compose_usr_prompt(    task = task, instructions = instructions, output = output,    style = style, examples = examples  )  res <- db |>   query_gpt_on_column(     \"commenti\", sys_prompt = sys_prompt, usr_prompt = usr_prompt   )  res }"},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/ubep.gpt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ubep.gpt: A basic/simple interface to OpenAI’s GPT API — ubep.gpt-package","title":"ubep.gpt: A basic/simple interface to OpenAI’s GPT API — ubep.gpt-package","text":"goal `ubep.gpt` provide basic/simple interface OpenAI's GPT API. package designed work (.e., query ) dataframes/tibbles, simplify process querying API.","code":""},{"path":[]},{"path":"https://ubesp-dctv.github.io/ubep.gpt/reference/ubep.gpt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ubep.gpt: A basic/simple interface to OpenAI’s GPT API — ubep.gpt-package","text":"Maintainer: Corrado Lanera corrado.lanera@ubep.unipd.(ORCID)","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/news/index.html","id":"ubepgpt-021","dir":"Changelog","previous_headings":"","what":"ubep.gpt 0.2.1","title":"ubep.gpt 0.2.1","text":"Add option return NA API returns error; apply gpt_query gpt_query_on_column functions (.e., base get_completion_from_messages function).","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/news/index.html","id":"ubepgpt-020","dir":"Changelog","previous_headings":"","what":"ubep.gpt 0.2.0","title":"ubep.gpt 0.2.0","text":"Removed dependency openai favour httr jsonlite directly Now queries can made personalized endpoints. create_usr_data_prompter now works empty characters (treated NULL). Now compose_prompt_api correctly manage empty prompts.","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/news/index.html","id":"ubepgpt-011","dir":"Changelog","previous_headings":"","what":"ubep.gpt 0.1.1","title":"ubep.gpt 0.1.1","text":"100% coverage passed Activated tests CI","code":""},{"path":"https://ubesp-dctv.github.io/ubep.gpt/news/index.html","id":"ubepgpt-010","dir":"Changelog","previous_headings":"","what":"ubep.gpt 0.1.0","title":"ubep.gpt 0.1.0","text":"functions tested. Prompt compositors (.e., compose_prompt, compose_usr_prompt, compose_sys_prompt, create_usr_data_prompter) now always return character vector (possibly length 0). query_gpt_on_column now accepts sys_prompt usr_prompt arguments customize user system prompts. (fix #1) Changed functions names uniform. .e., compose_prompt_user compose_prompt_system now called compose_usr_prompt compose_sys_prompt; usr_msg sys_msg arguments now called usr_prompt sys_prompt. (fix #2) Added zzz.R startup messages checking API keys. Update README examples usage. Setup development environment. Initial setup CorradoLanera/gpt-template.","code":""}]
